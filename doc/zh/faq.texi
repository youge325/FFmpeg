\input texinfo @c -*- texinfo -*-
@documentencoding UTF-8

@settitle FFmpeg 常见问题
@titlepage
@center @titlefont{FFmpeg 常见问题}
@end titlepage

@top

@contents

@chapter 常见问题

@section 为什么 FFmpeg 不支持功能 [xyz]？

因为还没有人承担这项任务。FFmpeg 的开发是由各个开发者认为重要的任务所驱动的。
如果某个功能对你很重要，最好的方式是自己动手实现，或者赞助一位开发者来完成。

@section FFmpeg 不支持编解码器 XXX。可以包含一个 Windows DLL 加载器来支持它吗？

不行。Windows DLL 不可移植、体积臃肿且通常速度较慢。
而且 FFmpeg 致力于原生支持所有编解码器。
DLL 加载器不利于实现这一目标。

@section 虽然这个格式似乎被 ffmpeg 支持，但我无法读取这个文件。

即使 ffmpeg 能读取容器格式，它可能不支持其中所有的编解码器。请查阅 ffmpeg 文档中支持的编解码器列表。

@section Windows 支持哪些编解码器？

除非安装一些额外的编解码器，Windows 对 MPEG 等标准格式的支持并不好。

以下视频编解码器列表应该在大多数 Windows 系统上可用：
@table @option
@item msmpeg4v2
.avi/.asf
@item msmpeg4
仅 .asf
@item wmv1
仅 .asf
@item wmv2
仅 .asf
@item mpeg4
仅在安装了 ffdshow 或 Xvid 等 MPEG-4 编解码器时可用。
@item mpeg1video
仅 .mpg
@end table
注意，ASF 文件在 Windows 中通常使用 .wmv 或 .wma 扩展名。还需要注意的是，Microsoft 声称对 ASF 格式拥有专利，并可能起诉或威胁使用非 Microsoft 软件创建 ASF 文件的用户。强烈建议尽可能避免使用 ASF。

以下音频编解码器列表应该在大多数 Windows 系统上可用：
@table @option
@item adpcm_ima_wav
@item adpcm_ms
@item pcm_s16le
始终可用
@item libmp3lame
需要安装 LAME 等 MP3 编解码器。
@end table


@chapter 编译

@section @code{error: can't find a register in class 'GENERAL_REGS' while reloading 'asm'}

这是 gcc 的一个 bug。请不要向我们报告。请向 gcc 开发者报告。注意，我们不会为 gcc 的 bug 添加变通方案。

另外注意，（某些）gcc 开发者认为这不是 bug，或者不是他们应该修复的 bug：
@url{https://gcc.gnu.org/bugzilla/show_bug.cgi?id=11203}。
然而，他们中有些人甚至分不清不可判定问题和 NP-hard 问题的区别……

@section 我已经用发行版的包管理器安装了这个库。为什么 @command{configure} 找不到它？

发行版通常将库拆分为多个包。主包包含运行使用该库的程序所需的文件。开发包包含构建使用该库的程序所需的文件。有时，文档和/或数据也在单独的包中。

要构建 FFmpeg，你需要安装开发包。它通常命名为 @file{libfoo-dev} 或 @file{libfoo-devel}。你可以在构建完成后卸载它，但请务必保留主包。

@section 如何让 @command{pkg-config} 找到我的库？

在你的库目录附近，会有一个（或多个）@file{.pc} 文件在 @file{pkgconfig} 目录中。你需要设置环境变量，使 @command{pkg-config} 指向这些文件。

如果你需要@emph{添加}目录到 @command{pkg-config} 的搜索列表中（典型用例：单独安装的库），将其添加到 @code{$PKG_CONFIG_PATH}：

@example
export PKG_CONFIG_PATH=/opt/x264/lib/pkgconfig:/opt/opus/lib/pkgconfig
@end example

如果你需要@emph{替换} @command{pkg-config} 的搜索列表（典型用例：交叉编译），在 @code{$PKG_CONFIG_LIBDIR} 中设置：

@example
export PKG_CONFIG_LIBDIR=/home/me/cross/usr/lib/pkgconfig:/home/me/cross/usr/local/lib/pkgconfig
@end example

如果你需要知道库的内部依赖关系（典型用途：静态链接），在 @command{pkg-config} 中添加 @code{--static} 选项：

@example
./configure --pkg-config-flags=--static
@end example

@section 交叉编译时如何使用 @command{pkg-config}？

最好的方式是在交叉编译环境中安装 @command{pkg-config}。它会自动使用交叉编译库。

你也可以使用主机环境的 @command{pkg-config}，通过在 @command{configure} 中明确指定 @code{--pkg-config=pkg-config}。在这种情况下，你必须使用 @code{PKG_CONFIG_LIBDIR} 将 @command{pkg-config} 指向正确的目录，如上一条所述。

作为中间方案，你可以在交叉编译环境中放置一个脚本，该脚本在设置 @code{PKG_CONFIG_LIBDIR} 后调用主机的 @command{pkg-config}。脚本内容如下：

@example
#!/bin/sh
PKG_CONFIG_LIBDIR=/path/to/cross/lib/pkgconfig
export PKG_CONFIG_LIBDIR
exec /usr/bin/pkg-config "$@@"
@end example

@chapter 使用

@section ffmpeg 不工作；出了什么问题？

在构建之前，尝试在 ffmpeg 源代码目录中执行 @code{make distclean}。
如果这不起作用，请参阅
(@url{https://ffmpeg.org/bugreports.html})。

@section 如何将单张图片编码成视频？

首先，将你的图片重命名为按数字顺序排列。
例如，img1.jpg, img2.jpg, img3.jpg,...
然后你可以运行：

@example
ffmpeg -f image2 -i img%d.jpg /tmp/a.mpg
@end example

注意 @samp{%d} 会被替换为图片编号。

@file{img%03d.jpg} 表示序列 @file{img001.jpg}、@file{img002.jpg} 等。

使用 @option{-start_number} 选项可以声明序列的起始编号。
如果你的序列不是从 @file{img001.jpg} 开始但仍按数字顺序排列，这很有用。以下示例将从 @file{img100.jpg} 开始：

@example
ffmpeg -f image2 -start_number 100 -i img%d.jpg /tmp/a.mpg
@end example

如果你有大量图片需要重命名，可以使用以下命令简化操作。该命令使用 Bourne shell 语法，将当前目录中所有匹配 @code{*jpg} 的文件符号链接到 @file{/tmp} 目录，按 @file{img001.jpg}、@file{img002.jpg} 等顺序排列。

@example
x=1; for i in *jpg; do counter=$(printf %03d $x); ln -s "$i" /tmp/img"$counter".jpg; x=$(($x+1)); done
@end example

如果你想按最早修改时间排序，将 @code{$(ls -r -t *jpg)} 替换 @code{*jpg}。

然后运行：

@example
ffmpeg -f image2 -i /tmp/img%03d.jpg /tmp/a.mpg
@end example

相同的逻辑适用于 ffmpeg 能读取的任何图片格式。

你也可以使用 @command{cat} 将图片通过管道传递给 ffmpeg：

@example
cat *.jpg | ffmpeg -f image2pipe -c:v mjpeg -i - output.mpg
@end example

@section 如何将视频编码为单张图片？

使用：

@example
ffmpeg -i movie.mpg movie%d.jpg
@end example

输入的 @file{movie.mpg} 将被转换为 @file{movie1.jpg}、@file{movie2.jpg} 等。

除了依赖文件格式自动识别，你也可以使用
@table @option
@item -c:v ppm
@item -c:v png
@item -c:v mjpeg
@end table
来强制指定编码。

将其应用于上一个示例：
@example
ffmpeg -i movie.mpg -f image2 -c:v mjpeg menu%d.jpg
@end example

注意没有 "jpeg" 编解码器。请使用 "mjpeg" 替代。

@section 为什么使用多线程 MPEG* 编码时画质会略有下降？

对于多线程 MPEG* 编码，编码的切片必须是独立的，否则线程 n 实际上必须等待线程 n-1 完成，所以画质有轻微下降是合理的。这不是一个 bug。

@section 如何从标准输入读取或写入标准输出？

使用 @file{-} 作为文件名。

@section -f jpeg 不工作。

尝试 '-f image2 test%d.jpg'。

@section 为什么我不能改变帧率？

某些编解码器（如 MPEG-1/2）只允许少量固定帧率。
请使用 -c:v 命令行选项选择不同的编解码器。

@section 如何用 ffmpeg 编码 Xvid 或 DivX 视频？

Xvid 和 DivX（4+ 版本）都是 ISO MPEG-4 标准的实现（注意还有许多其他编码格式使用相同的标准）。因此，使用 '-c:v mpeg4' 来编码这些格式。MPEG-4 编码文件中存储的默认 fourcc 将是 'FMP4'。如果你想要不同的 fourcc，使用 '-vtag' 选项。例如，'-vtag xvid' 将强制存储 'xvid' 作为视频 fourcc，而不是默认值。

@section 编码高质量 MPEG-4 的好参数是什么？

'-mbd rd -flags +mv4+aic -trellis 2 -cmp 2 -subcmp 2 -g 300 -pass 1/2'，
可以尝试的参数：'-bf 2'、'-mpv_flags qp_rd'、'-mpv_flags mv0'、'-mpv_flags skip_rd'。

@section 编码高质量 MPEG-1/MPEG-2 的好参数是什么？

'-mbd rd -trellis 2 -cmp 2 -subcmp 2 -g 100 -pass 1/2'，
但注意 '-g 100' 可能会导致某些解码器出现问题。
可以尝试的参数：'-bf 2'、'-mpv_flags qp_rd'、'-mpv_flags mv0'、'-mpv_flags skip_rd'。

@section 用 ffmpeg 编码的隔行视频看起来很差，怎么回事？

你应该使用 '-flags +ilme+ildct'，对于隔行素材可能还需要 '-flags +alt'，如果结果看起来确实很乱，可以尝试 '-top 0/1'。

@section 如何读取 DirectShow 文件？

如果你使用 @code{./configure --enable-avisynth} 构建了 FFmpeg（仅适用于 MinGW/Cygwin 平台），那么你可以使用 DirectShow 能读取的任何文件作为输入。

只需创建一个 "input.avs" 文本文件，内容为以下单行：
@example
DirectShowSource("C:\path to your file\yourfile.asf")
@end example
然后将该文本文件传递给 ffmpeg：
@example
ffmpeg -i input.avs
@end example

有关 AviSynth 的任何其他帮助，请访问 @uref{http://www.avisynth.org/, AviSynth 主页}。

@section 如何合并视频文件？

"合并"视频文件是一个比较模糊的说法。以下列表解释了不同类型的"合并"以及它们在 FFmpeg 中的处理方式。合并视频文件可能意味着：

@itemize

@item
将它们依次排列：这称为@emph{连接}（concatenate，简称 concat），在@ref{如何连接视频文件, 本 FAQ 中}有详细说明。

@item
将它们放在同一个文件中，让用户在不同版本之间选择（例如：不同的音频语言）：这称为@emph{复用}（multiplex，简称 mux），通过简单地使用多个 @option{-i} 选项调用 ffmpeg 即可完成。

@item
对于音频，将所有声道放入单个流中（例如：两个单声道流合为一个立体声流）：这有时称为@emph{合并}（merge），可以使用 @url{ffmpeg-filters.html#amerge, @code{amerge}} 滤镜完成。

@item
对于音频，将一个叠加在另一个之上播放：这称为@emph{混音}（mix），可以通过先将它们合并为单个流，然后使用 @url{ffmpeg-filters.html#pan, @code{pan}} 滤镜按需混合声道来完成。

@item
对于视频，将两者同时显示，并排或一个叠加在另一个的部分之上；可以使用 @url{ffmpeg-filters.html#overlay, @code{overlay}} 视频滤镜完成。

@end itemize

@anchor{如何连接视频文件}
@section 如何连接视频文件？

根据具体情况有多种解决方案。

@subsection 使用 concat @emph{滤镜}连接

FFmpeg 有一个专门设计的 @url{ffmpeg-filters.html#concat, @code{concat}} 滤镜，文档中有使用示例。如果你需要重新编码，推荐使用此方法。

@subsection 使用 concat @emph{解复用器}连接

FFmpeg 有一个 @url{ffmpeg-formats.html#concat, @code{concat}} 解复用器，当你想避免重新编码且你的格式不支持文件级别连接时可以使用它。

@subsection 使用 concat @emph{协议}连接（文件级别）

FFmpeg 有一个专门设计的 @url{ffmpeg-protocols.html#concat, @code{concat}} 协议，文档中有使用示例。

一些多媒体容器（MPEG-1、MPEG-2 PS、DV）允许通过简单地拼接包含它们的文件来连接视频。

因此，你可以通过先将多媒体文件转码为这些特权格式，然后使用简单的 @code{cat} 命令（或 Windows 下同样简单的 @code{copy} 命令），最后再转码回你选择的格式来连接多媒体文件。

@example
ffmpeg -i input1.avi -qscale:v 1 intermediate1.mpg
ffmpeg -i input2.avi -qscale:v 1 intermediate2.mpg
cat intermediate1.mpg intermediate2.mpg > intermediate_all.mpg
ffmpeg -i intermediate_all.mpg -qscale:v 2 output.avi
@end example

此外，你可以使用 @code{concat} 协议代替 @code{cat} 或 @code{copy}，这样可以避免创建可能很大的中间文件。

@example
ffmpeg -i input1.avi -qscale:v 1 intermediate1.mpg
ffmpeg -i input2.avi -qscale:v 1 intermediate2.mpg
ffmpeg -i concat:"intermediate1.mpg|intermediate2.mpg" -c copy intermediate_all.mpg
ffmpeg -i intermediate_all.mpg -qscale:v 2 output.avi
@end example

注意你可能需要转义字符 "|"，因为它在许多 shell 中是特殊字符。

还可以使用命名管道（如果你的平台支持的话）：

@example
mkfifo intermediate1.mpg
mkfifo intermediate2.mpg
ffmpeg -i input1.avi -qscale:v 1 -y intermediate1.mpg < /dev/null &
ffmpeg -i input2.avi -qscale:v 1 -y intermediate2.mpg < /dev/null &
cat intermediate1.mpg intermediate2.mpg |\
ffmpeg -f mpeg -i - -c:v mpeg4 -c:a libmp3lame output.avi
@end example

@subsection 使用原始音视频连接

类似地，yuv4mpegpipe 格式，以及原始视频、原始音频编解码器也允许连接，且转码步骤几乎是无损的。当使用多个 yuv4mpegpipe 时，需要从除第一个之外的所有流中丢弃第一行。这可以通过管道传递到 @code{tail} 来完成，如下所示。注意，当通过管道传递到 @code{tail} 时，你必须使用命令分组 @code{@{  ;@}} 来正确地后台运行。

例如，假设我们想要将两个 FLV 文件连接成一个 output.flv 文件：

@example
mkfifo temp1.a
mkfifo temp1.v
mkfifo temp2.a
mkfifo temp2.v
mkfifo all.a
mkfifo all.v
ffmpeg -i input1.flv -vn -f u16le -c:a pcm_s16le -ac 2 -ar 44100 - > temp1.a < /dev/null &
ffmpeg -i input2.flv -vn -f u16le -c:a pcm_s16le -ac 2 -ar 44100 - > temp2.a < /dev/null &
ffmpeg -i input1.flv -an -f yuv4mpegpipe - > temp1.v < /dev/null &
@{ ffmpeg -i input2.flv -an -f yuv4mpegpipe - < /dev/null | tail -n +2 > temp2.v ; @} &
cat temp1.a temp2.a > all.a &
cat temp1.v temp2.v > all.v &
ffmpeg -f u16le -c:a pcm_s16le -ac 2 -ar 44100 -i all.a \
       -f yuv4mpegpipe -i all.v \
       -y output.flv
rm temp[12].[av] all.[av]
@end example

@section 使用 @option{-f lavfi} 时，音频莫名其妙变成了单声道。

使用 @option{-dumpgraph -} 来查看声道布局在哪里丢失了。

最有可能是通过 @code{auto-inserted aresample}。尝试理解为什么在那个位置需要转换滤镜。

在输出之前是一个可能的位置，因为 @option{-f lavfi} 目前只支持打包的 S16。

然后在滤镜图中显式插入正确的 @code{aformat}，指定精确的格式。

@example
aformat=sample_fmts=s16:channel_layouts=stereo
@end example

@section 为什么 FFmpeg 看不到我的 VOB 文件中的字幕？

VOB 和其他一些格式没有描述文件中所有内容的全局头。相反，应用程序应该扫描文件来查看它包含什么。由于 VOB 文件通常很大，只会扫描文件开头部分。如果字幕只出现在文件的后面部分，它们不会被初始检测到。

某些应用程序（包括 @code{ffmpeg} 命令行工具）只能处理在初始扫描期间检测到的流；后来检测到的流会被忽略。

初始扫描的大小由两个选项控制：@code{probesize}（默认约 5@tie{}Mo）和 @code{analyzeduration}（默认 5,000,000@tie{}µs = 5@tie{}s）。要检测到字幕流，两个值都必须足够大。

@section 为什么 @command{ffmpeg} 的 @option{-sameq} 选项被移除了？应该用什么替代？

@option{-sameq} 选项的含义是"相同量化器"，只在非常有限的情况下有意义。不幸的是，很多人误以为它是"相同质量"，并在不合适的地方使用它：它大致有预期的视觉效果，但以非常低效的方式实现。

每个编码器都有自己的选项来设置质量与大小的平衡，使用你所用编码器的选项来将质量级别设置到你满意的程度。最常用的选项是 @option{-qscale} 和 @option{-qmax}，但你应该仔细阅读你选择的编码器的文档。

@section 我有一个拉伸的视频，为什么缩放不能修复它？

许多视频编解码器和格式可以存储视频的@emph{宽高比}：这是全图像（DAR，显示宽高比）或单个像素（SAR，采样宽高比）的宽度与高度之比。例如，分辨率为 640×350 的 EGA 屏幕的 DAR 为 4:3，SAR 为 35:48。

大多数静态图像处理使用方形像素，即 1:1 SAR，但许多视频标准，特别是模数转换时代的标准，使用非方形像素。

FFmpeg 中的大多数处理滤镜会处理宽高比以避免拉伸图像：裁剪调整 DAR 以保持 SAR 不变，缩放调整 SAR 以保持 DAR 不变。

如果你想拉伸或"取消拉伸"图像，你需要使用 @url{ffmpeg-filters.html#setdar_002c-setsar, @code{setdar 或 setsar 滤镜}} 覆盖信息。

不要忘记仔细检查原始视频，确认拉伸是来自图像还是宽高比信息。

例如，要修复一个编码错误的 EGA 截图，使用以下命令，第一个将其放大到方形像素，第二个设置正确的宽高比，第三个避免转码（根据格式/编解码器/播放器/月相的不同可能不工作）：

@example
ffmpeg -i ega_screen.nut -vf scale=640:480,setsar=1 ega_screen_scaled.nut
ffmpeg -i ega_screen.nut -vf setdar=4/3 ega_screen_anamorphic.nut
ffmpeg -i ega_screen.nut -aspect 4/3 -c copy ega_screen_overridden.nut
@end example

@anchor{background task}
@section 如何将 ffmpeg 作为后台任务运行？

ffmpeg 在执行操作时通常会检查控制台输入，例如 "q" 用于停止、"?" 用于显示帮助。ffmpeg 没有办法检测它是否在后台运行。
当它检查控制台输入时，可能导致在后台运行 ffmpeg 的进程挂起。

要阻止这些输入检查，允许 ffmpeg 作为后台任务运行，请在 ffmpeg 调用中使用 @url{ffmpeg.html#stdin-option, @code{-nostdin} 选项}。无论你是在 shell 中运行 ffmpeg 还是通过操作系统 API 在自己的进程中调用 ffmpeg，这都是有效的。

作为替代方案，当你在 shell 中运行 ffmpeg 时，可以将标准输入重定向到 @code{/dev/null}（在 Linux 和 macOS 上）或 @code{NUL}（在 Windows 上）。你可以在 ffmpeg 调用中进行此重定向，也可以在调用 ffmpeg 的 shell 脚本中进行。

例如：

@example
ffmpeg -nostdin -i INPUT OUTPUT
@end example

或者（在 Linux、macOS 和其他类 UNIX shell 上）：

@example
ffmpeg -i INPUT OUTPUT </dev/null
@end example

或者（在 Windows 上）：

@example
ffmpeg -i INPUT OUTPUT <NUL
@end example

@section 如何防止 ffmpeg 挂起并显示 @emph{suspended (tty output)} 消息？

如果你在后台运行 ffmpeg，可能会发现它的进程挂起了。
可能会出现类似 @emph{suspended (tty output)} 的消息。问题是如何防止进程被挂起。

例如：

@example
% ffmpeg -i INPUT OUTPUT &> ~/tmp/log.txt &
[1] 93352
%
[1]  + suspended (tty output)  ffmpeg -i INPUT OUTPUT &>
@end example

尽管消息显示 "tty output"，但实际问题是 ffmpeg 在运行时通常会检查控制台输入。操作系统检测到这一点，并将进程挂起直到你可以将其切换到前台并处理它。

解决方案是使用正确的技术告诉 ffmpeg 不要检查控制台输入。你可以使用 @url{ffmpeg.html#stdin-option, @code{-nostdin} 选项}，或使用 @code{< /dev/null} 重定向标准输入。
详见 FAQ @ref{background task, @emph{如何将 ffmpeg 作为后台任务运行？}}。

@chapter 开发

@section 是否有展示如何使用 FFmpeg 库（特别是 libavcodec 和 libavformat）的示例？

有的。请查看源代码仓库中的 @file{doc/examples} 目录，也可以在线查看：
@url{https://github.com/FFmpeg/FFmpeg/tree/master/doc/examples}。

示例默认也会安装，通常在 @code{$PREFIX/share/ffmpeg/examples}。

你也可以阅读 FFmpeg 文档中的开发者指南。或者，查看已经集成 FFmpeg 的众多开源项目之一的源代码 (@url{projects.html})。

@section 你能支持我的 C 编译器 XXX 吗？

这要看情况。如果你的编译器符合 C99 标准，那么支持它的补丁可能会受到欢迎，前提是它们不会用与编译器相关的 @code{#ifdef} 污染源代码。

@section Microsoft Visual C++ 支持吗？

是的。请参阅 FFmpeg 文档中的 @uref{platform.html, Microsoft Visual C++} 部分。

@section 你能添加 automake、libtool 或 autoconf 支持吗？

不能。这些工具太臃肿，会使构建过程复杂化。

@section 为什么不用面向对象的 C++ 重写 FFmpeg？

FFmpeg 已经以高度模块化的方式组织，不需要用正式的面向对象语言重写。此外，许多开发者偏爱纯 C 语言；它对他们很有效。关于这个话题的更多论点，请阅读 @uref{https://web.archive.org/web/20111004021423/http://kernel.org/pub/linux/docs/lkml/#s15, "编程宗教"}。

@section 为什么 ffmpeg 程序没有调试符号？

构建过程会创建 @command{ffmpeg_g}、@command{ffplay_g} 等包含完整调试信息的二进制文件。这些二进制文件被裁剪后创建 @command{ffmpeg}、@command{ffplay} 等。如果你需要调试信息，请使用 *_g 版本。

@section 我不喜欢 LGPL，我可以在 GPL 下贡献代码吗？

可以，只要代码是可选的，并且可以容易且干净地放在 #if CONFIG_GPL 下而不破坏任何东西。因此，例如，一个新的编解码器或滤镜可以在 GPL 下，而 LGPL 代码的 bug 修复则不行。

@section 我在 C 应用程序中使用 FFmpeg，但链接器抱怨库本身缺少符号。

FFmpeg 默认构建静态库。在静态库中，依赖关系不会被处理。这有两个后果。首先，你必须按依赖顺序指定库：@code{-lavdevice} 必须在 @code{-lavformat} 之前，@code{-lavutil} 必须在所有其他之后，等等。其次，FFmpeg 中使用的外部库也必须被指定。

获取按依赖顺序排列的所需库完整列表的简单方法是使用 @code{pkg-config}。

@example
c99 -o program program.c $(pkg-config --cflags --libs libavformat libavcodec)
@end example

详见 @file{doc/example/Makefile} 和 @file{doc/example/pc-uninstalled}。

@section 我在 C++ 应用程序中使用 FFmpeg，但链接器抱怨似乎存在的符号缺失。

FFmpeg 是一个纯 C 项目，因此要在 C++ 应用程序中使用这些库，你需要明确声明你正在使用 C 库。你可以通过用 @code{extern "C"} 包裹 FFmpeg 的头文件包含来实现。

参见 @url{http://www.parashift.com/c++-faq-lite/mixing-c-and-cpp.html#faq-32.3}

@section 我在 C++ 应用程序中使用 libavutil，但编译器抱怨 'UINT64_C' 未在此作用域中声明

FFmpeg 是一个使用 C99 数学特性的纯 C 项目，为了让 C++ 使用它们，你需要在 CXXFLAGS 中追加 -D__STDC_CONSTANT_MACROS

@section 我有一个在内存中的文件或与 *open/*read/ libc 不同的 API，如何用 libavformat 使用它？

你需要使用 @code{avio_alloc_context} 创建一个自定义 AVIOContext，参见 FFmpeg 源代码中的 @file{libavformat/aviobuf.c} 和 MPlayer 或 MPlayer2 源代码中的 @file{libmpdemux/demux_lavf.c}。

@section 关于 ffv1、msmpeg4、asv1、4xm 的文档在哪里？

参见 @url{https://www.ffmpeg.org/~michael/}

@section 如何将 H.263-RTP（以及 RTP 中的其他编解码器）传递给 libavcodec？

尽管 RTP 因其面向网络的特性而有些特殊，但它和其他容器格式一样。你需要在将载荷传递给 libavcodec 之前@emph{解复用} RTP。在这个特定情况下，请参阅 RFC 4629 了解应该如何操作。

@section AVStream.r_frame_rate 是错误的，它比帧率大得多。

@code{r_frame_rate} 不是平均帧率，它是能准确表示所有时间戳的最小帧率。所以如果它比平均值大，那不是错误！
例如，如果你有混合的 25 和 30 fps 内容，那么 @code{r_frame_rate} 将是 150（它是最小公倍数）。
如果你在寻找平均帧率，请参见 @code{AVStream.avg_frame_rate}。

@section 为什么 @code{make fate} 没有运行所有测试？

确保你有 fate-suite 样本，并且 @code{SAMPLES} Make 变量或 @code{FATE_SAMPLES} 环境变量或 @code{--samples} @command{configure} 选项设置为正确的路径。

@section 为什么 @code{make fate} 找不到样本？

你的样本路径中是否有 @code{~} 字符来表示主目录？该值的使用方式使得 shell 无法展开它，导致 FATE 找不到文件。只需将 @code{~} 替换为完整路径即可。

@bye
